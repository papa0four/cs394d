{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 2.3: Loss Functions in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=tensor([[-1.7157,  0.2723,  0.2605,  0.8049,  0.9360,  0.1178, -1.1467, -1.0958,\n",
      "          0.1131, -0.7971],\n",
      "        [-0.2133,  1.5616, -0.5865,  2.0435,  2.0033,  0.2643, -0.1744, -0.1345,\n",
      "         -0.8995, -0.7836],\n",
      "        [ 0.2003,  0.8282,  0.3317,  0.1174, -0.9056,  0.0381, -0.2074, -0.0956,\n",
      "         -0.0346, -0.3876],\n",
      "        [-0.9700,  1.0799,  0.7568, -0.2424,  1.5821, -0.9750, -1.6852,  0.1128,\n",
      "          0.5962, -0.6789],\n",
      "        [-0.7722,  0.7714,  1.2839, -0.4485,  0.5791,  0.9248, -0.9611,  0.1641,\n",
      "          0.4762,  0.6230],\n",
      "        [-0.1726,  1.5206, -0.5802,  0.1347, -0.7945, -1.4778,  2.1264, -0.5404,\n",
      "         -0.0097,  0.2387],\n",
      "        [ 0.4563,  0.6463, -1.0185, -0.9843, -0.9828, -0.1481,  0.5168, -0.4819,\n",
      "          0.2391,  0.1521],\n",
      "        [-1.4396, -0.9947, -0.0126,  0.7578, -1.7899, -2.2030, -0.4822, -0.3504,\n",
      "          2.1288, -1.7539],\n",
      "        [-0.0904,  0.0320,  0.8591,  0.7712, -0.8886, -1.3279,  2.4753,  0.0827,\n",
      "         -0.5207, -1.1707],\n",
      "        [-0.5746,  0.9325, -1.6450, -1.1692, -0.0427,  1.4201,  1.5238,  0.4393,\n",
      "          0.4468,  1.2490],\n",
      "        [-0.2102, -0.2818, -0.4786, -0.5583, -1.6363, -1.5156,  0.1402,  0.1509,\n",
      "          1.2189, -1.2617],\n",
      "        [-1.0943,  0.3399,  0.8991, -0.5764, -0.4588, -0.0123,  1.3056, -0.9166,\n",
      "         -0.1302,  1.1880],\n",
      "        [-0.9675,  0.3276, -1.1806,  0.2062, -0.2480, -2.8674,  0.1462,  2.0322,\n",
      "          0.7153, -1.0040],\n",
      "        [ 1.3080, -0.9621, -0.6641,  1.4105,  0.4478, -0.1768, -0.2851, -0.0354,\n",
      "         -0.9031,  1.0086],\n",
      "        [-0.3190, -1.0323, -0.4553, -1.4498,  1.3904,  1.1656,  0.8933,  0.6319,\n",
      "          1.6627, -0.0478],\n",
      "        [ 0.2977,  1.4427, -0.0508, -1.8790,  1.4097, -0.5943, -0.7873, -0.8924,\n",
      "         -0.1898,  1.4705],\n",
      "        [-0.5662, -0.9890, -0.1226,  1.2666,  0.6411, -1.4013,  0.4722,  0.0478,\n",
      "         -0.5292, -0.3136],\n",
      "        [-0.1114, -1.2268, -1.2321, -0.1051, -2.1346,  1.5511, -1.0803,  0.9754,\n",
      "          0.0941,  0.9331],\n",
      "        [ 0.8170, -0.2028, -0.7960,  0.4188,  0.3801, -0.4092, -1.8298,  0.8078,\n",
      "          1.1483,  0.3080],\n",
      "        [-0.5957, -1.0133, -1.7151, -0.1353, -0.0835, -1.0019, -0.2133, -1.5882,\n",
      "          0.1386, -0.7265]]) y=tensor([[ 0.3381],\n",
      "        [ 0.2172],\n",
      "        [-0.0830],\n",
      "        [-0.0172],\n",
      "        [ 0.0485],\n",
      "        [-0.0273],\n",
      "        [-1.8593],\n",
      "        [-0.3281],\n",
      "        [-0.0777],\n",
      "        [-0.6310],\n",
      "        [-0.8572],\n",
      "        [ 0.0847],\n",
      "        [ 2.3084],\n",
      "        [-1.7997],\n",
      "        [ 1.7187],\n",
      "        [-0.5488],\n",
      "        [-1.2559],\n",
      "        [-0.3247],\n",
      "        [-0.7841],\n",
      "        [ 0.9273]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(20, 10)\n",
    "y = torch.randn(20, 1)\n",
    "print(f'{x=} {y=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4766],\n",
      "        [-0.5957],\n",
      "        [ 0.0404],\n",
      "        [ 0.2184],\n",
      "        [-0.2866],\n",
      "        [ 0.2843],\n",
      "        [ 0.5203],\n",
      "        [ 0.7052],\n",
      "        [-0.2060],\n",
      "        [-0.1365],\n",
      "        [ 0.7983],\n",
      "        [-0.2766],\n",
      "        [ 0.8562],\n",
      "        [ 0.4079],\n",
      "        [ 0.1365],\n",
      "        [ 0.6993],\n",
      "        [ 0.0924],\n",
      "        [ 0.1332],\n",
      "        [ 0.9500],\n",
      "        [ 0.5460]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred_y = model(x)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3845, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# y, pred_y\n",
    "loss = torch.nn.functional.mse_loss(pred_y, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3845, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse_loss(pred_y, y):\n",
    "    return torch.mean((pred_y - y) ** 2)\n",
    "\n",
    "mse_loss(pred_y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "y = (torch.randn(20, 1) > 0).float()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7947, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# if loss > 0.7, the model would be better if we flipped the labels\n",
    "# if loss < 0.7 then the model is good\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_y, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 1, 2, 0, 1, 2, 0, 1, 2, 2, 0, 1, 1, 2, 2, 0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "n_classes = 3\n",
    "model = torch.nn.Linear(10, n_classes)\n",
    "# y = (torch.randn(20) > 0).long() + (torch.randn(20) > 0).long() didnt work from lecture\n",
    "y = torch.randint(0, n_classes, (20,)) # this worked\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1144, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred_y = model(x)\n",
    "loss = torch.nn.functional.cross_entropy(pred_y, y)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
