{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3.3: Output Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recap: Deep Networks\n",
    "\n",
    "**Universal Approximation Theorem**\n",
    "\n",
    "A two-layer deep network can approximate any continuous function.\n",
    "\n",
    "We might not always want continuous (real-valued) outputs\n",
    "* How can we convert the real value to what we want?\n",
    "\n",
    "$x\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{o}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs and Outputs of Networks\n",
    "\n",
    "Input: $\\text{x}\\ \\in\\ \\mathbb{R}^{n}$\n",
    "\n",
    "Output: $\\text{o}\\ =\\ f_{\\theta}(\\text{x})$\n",
    "\n",
    "* $f_{\\theta}$: deep network\n",
    "\n",
    "$x\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{o}$\n",
    "\n",
    "Output transformations: $g$\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;$\\psi\\ :\\ f_{\\theta}\\ \\circ\\ g$\n",
    "\n",
    "#### Positive Regression\n",
    "\n",
    "Positive regression: $\\psi\\ :\\ \\mathbb{R}^{n}\\ \\rightarrow\\ \\mathbb{R}_{+}$\n",
    "\n",
    "Option 1: ReLU\n",
    "* $\\hat{y}\\ =\\ g(\\text{o})\\ =\\ \\text{max}(\\text{o},\\ 0)$\n",
    "\n",
    "Option 2: Soft ReLU\n",
    "* $\\hat{y}\\ =\\ g(\\text{o})\\ =\\ \\text{log}(1\\ +\\ e^{\\text{o}})$\n",
    "\n",
    "$x\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{...}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{g}\\ \\rightarrow\\ \\hat{y}$\n",
    "\n",
    "where $f_{\\theta}$ lies within the linear computation layers and $\\psi$ lies within all interim layers before computing $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "\n",
    "Regression: $\\psi\\ :\\ \\mathbb{R}^{n}\\ \\rightarrow\\ \\mathbb{R}$\n",
    "* Identity mappging: $g(\\text{o})\\ =\\ \\text{o}$\n",
    "\n",
    "$x\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{...}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{g(o) = o}\\ \\rightarrow\\ \\hat{y}$\n",
    "\n",
    "where $f_{\\theta}$ lies within the linear computation layers and $\\psi$ lies within all interim layers before computing $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Classification\n",
    "\n",
    "Binary classification $\\psi\\ :\\ \\mathbb{R}^{n}\\ \\rightarrow\\ [0,\\ 1]$\n",
    "\n",
    "$x\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{...}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{g}\\ \\rightarrow\\ \\hat{y}$\n",
    "\n",
    "where $f_{\\theta}$ lies within the linear computation layers and $\\psi$ lies within all interim layers before computing $\\hat{y}$\n",
    "\n",
    "Option 1: Thresholding\n",
    "* $\\hat{y}\\ =\\ g(\\text{o})\\ =\\ 1\\{\\text{o}\\ >\\ 0\\}$\n",
    "\n",
    "Option 2: Logistic Regression\n",
    "* $\\hat{y}\\ =\\ \\sigma(\\text{o})\\ =\\ \\frac{1}{1\\ +\\ e^{-\\text{o}}}$\n",
    "\n",
    "$x\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{...}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\sigma\\ \\rightarrow\\ \\hat{y}$\n",
    "\n",
    "where $f_{\\theta}$ lies within the linear computation layers and $\\psi$ lies within all interim layers before computing $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Classification\n",
    "\n",
    "Multi-class classification $\\psi\\ :\\ \\mathbb{R}^{n}\\ \\rightarrow\\ [1\\ ...\\ C]$\n",
    "\n",
    "$x\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{...}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{g}\\ \\rightarrow\\ \\hat{y}$\n",
    "\n",
    "where $f_{\\theta}$ lies within the linear computation layers and $\\psi$ lies within all interim layers before computing $\\hat{y}$\n",
    "\n",
    "Option 1: argmax\n",
    "* $\\hat{y}\\ =\\ \\text{arg max}(\\text{o})$\n",
    "\n",
    "Option 2: one-hot\n",
    "* $\\hat{\\text{y}}\\ =\\ [0,\\ ...,\\ 1,\\ ...,\\ 0]^{\\top}$\n",
    "* $\\hat{\\text{y}}_{i}\\ =\\ 1\\ \\text{if}\\ \\text{o}_{i}\\ \\ge\\ \\text{o}_{j}\\ \\forall_{j}$\n",
    "\n",
    "Option 3: softmax\n",
    "* $p(y)\\ =\\ \\text{softmax}(\\text{o})$\n",
    "\n",
    "$x\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{...}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{Softmax}\\ \\rightarrow\\ \\hat{y}$\n",
    "\n",
    "where $f_{\\theta}$ lies within the linear computation layers and $\\psi$ lies within all interim layers before computing $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Representations in Practice\n",
    "\n",
    "Do **not** add to model\n",
    "* Most output transformations are not differentiable (or hard to differentiate)\n",
    "* Model cannot train with them\n",
    "\n",
    "**Model Output**\n",
    "* Always output raw values\n",
    "\n",
    "$x\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{ReLU}\\ \\rightarrow\\ \\text{...}\\ \\rightarrow\\ \\text{Linear}\\ \\rightarrow\\ \\text{g}\\ \\rightarrow\\ \\hat{\\text{y}}$\n",
    "\n",
    "where $f_{\\theta}$ lies within the linear computation layers and $\\psi$ lies within all interim layers before computing $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Representations - TL;DR\n",
    "* Deep networks always output real values\n",
    "* Output transformations convert them into what you want\n",
    "* Train the network *without* output transformations!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
